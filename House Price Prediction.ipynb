{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 《計算機程式期末報告》\n",
    "\n",
    "#### 一、組員名單:\n",
    "\n",
    "1. 106207411 財管三   文永慷\n",
    "\n",
    "2. 106307031 地三土測 李睿莆\n",
    "\n",
    "3. 105207445 地四土測 柯騰達\n",
    "\n",
    "4. 105701051 應數四   黃健瑋\n",
    "\n",
    "\n",
    "#### 二、組員分工表:\n",
    "\n",
    "1. 106207411 財管三 文永慷 / \n",
    "閱讀相關文獻、影片處理、資料蒐集\n",
    "\n",
    "2. 106307031 地三土測 李睿莆 / \n",
    "閱讀相關文獻、資料處理、建立模型、測試與修改資料\n",
    "\n",
    "3. 105207445 地四土測 柯騰達 / \n",
    "閱讀相關文獻、資料處理、建立模型、測試與修改資料\n",
    "\n",
    "4. 105701051 應數四 黃健瑋 / \n",
    "閱讀相關文獻、資料蒐集、測試與修改資料\n",
    "\n",
    "#### 三、問題發想與動機:\n",
    "\n",
    "* 想嘗試建立不動產自動估價模型的原因為，現行房市資訊不透明，導致價格的決定權往往掌握在建商手裡，消費者只能以建商公布的價格做為參考依據。但應該需要有一個能夠公正推估房屋價格的方式供消費者使用，否則消費者只能夠從建商端知道房價，根本沒有與建商議價的能力，自動估價模型的建立即可滿足上述需求，提供民眾一個真實且可靠的參考價格，透過政府發佈的房地產買賣實價登錄資料建立模型，改善傳統人力估價高人力且時間成本的問題，且同時排除了人為估價可能衍生的人為主觀因素，並貫徹「用機器去處理，讓資料本身變成一個合理、乾淨、不會產生偏誤的情況」的概念，將來若是可將準確度及誤差進一步修正，即可提供民眾買房時一個客觀且公正的參考指標，將有助於遏止現行不動產市場可能出現的惡意炒價或是虛報價格的問題，是一個非常值得長久且持續研究的題目。\n",
    "\n",
    "#### 四、資料來源與解釋:\n",
    "\n",
    "* 兩年來政府部門之實價登錄資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輸入資料(模型變數選擇)\n",
    "* 數值型變數: 移轉總面積（土地、建物）、交易筆棟數（土地、建物、車位）、移轉層次、總樓層數、建物現況格局（房、衛、廳、隔間）、標的座標（X、Y）、標的經緯度、屋齡\n",
    "\n",
    "* 虛擬變數（Dummy Variable）: 建物使用分區（住、工、商、其他）、主要建材（8種）、主要用途（住家用、住商用、工業用、商業用）、建物型態（公寓、住宅大樓、華廈、套房）、有無管理單位、有無車位、車位種類（8種）\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輸出資料\n",
    "* 不動產單價(元/平方公尺)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from ipywidgets import interact_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資料前處理\n",
    "## 1. 不動產實價登錄資料篩選\n",
    "* 因透天厝的 AVM 是利用買賣房屋的總價建模，其餘建物型態則是需使用單價建模，故此次報告並不會將透天厝的資料也一起拿來訓練\n",
    "* 建物型態:公寓、住宅大樓、華廈、套房\n",
    "* 交易標的:土地+建物、土地+建物+車位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\owner\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (6,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "gpd_df_house = pd.read_csv('raw_houses.csv')\n",
    "gpd_df_house = gpd_df_house.fillna(\"\")\n",
    "gpd_df_house = gpd_df_house[((gpd_df_house['建物型態']=='公寓(5樓含以下無電梯)') | (gpd_df_house['建物型態']=='住宅大樓(11層含以上有電梯)') | (gpd_df_house['建物型態']=='華廈(10層含以下有電梯)') | (gpd_df_house['建物型態']=='套房(1房1廳1衛)'))]\n",
    "gpd_df_house = gpd_df_house[((gpd_df_house['交易標的']=='房地(土地+建物)')|(gpd_df_house['交易標的']=='房地(土地+建物)+車位'))]\n",
    "gpd_df_house = gpd_df_house[(gpd_df_house['county']=='台北市')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 不動產實價登錄資料清理\n",
    "* 因實價登錄資料中會留有一些特殊態樣的交易資料，例如:親友間交易、瑕疵屋交易、毛胚屋交易等等，這些特殊態樣交易型態的交易價格其實是非常異於市場行情的，因此在建立模型前應該透過實價登錄資料備註欄提供的資訊，將這些特殊態樣的交易資料清除，才不會使模型預測的價格偏離真實市場成交價格，下方羅列出57種特殊態樣的交易型態，皆為建立模型前須清除的交易資料\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean_based_on_note(df, a1s, a0s, a11s):\n",
    "    boolean_selected = pd.Series(np.array([False]*df.shape[0]))\n",
    "    for a1 in a1s:        \n",
    "        boolean_selected = (boolean_selected | df['備註'].str.contains(a1, na=False))  #包含此文字內容會進入備註欄==true\n",
    "        \n",
    "    for a0 in a0s:\n",
    "        boolean_selected = (boolean_selected & ~df['備註'].str.contains(a0, na=False)) #包含此文字不會進入備註欄==false\n",
    "        \n",
    "    for a11 in a11s:\n",
    "        boolean_selected = (boolean_selected | df['備註'].str.contains(a11, na=False))   #包含此文字內容會進入備註欄==true\n",
    "        \n",
    "    return boolean_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_note_flag(df, flag_name, a1s, a0s, a11s):\n",
    "    df[flag_name] = False\n",
    "    df.loc[boolean_based_on_note(df, a1s, a0s, a11s), flag_name] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\owner\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\strings.py:1954: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "set_note_flag(gpd_df_house, \"flag_毛胚屋\", \n",
    "            ['無.*隔間','毛胚','房間需自行隔間','未隔間'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_瑕疵物件\", \n",
    "            ['瑕疵物件','海砂屋','受損房屋','老舊','凶宅','祭祀公業','事故','非自然','無接水電','損壞','破損','滲*水','壁癌','屋況不佳','屋況.*差','屋況嚴重瑕疵','房屋.*半毀','房屋破舊','屋況需整理','屋況殘破','屋況不良','房屋.*已坍塌','房屋老舊','建物須整修','部分土地有人死亡','入口處狹小巷弄狹小','無接水接電','高壓電線正下方','多年無人使用','建物已毀損','死亡','事故','年久失修','廢墟','無法居住','面積流失','荒廢','河床侵蝕'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_公共設施保留地\", \n",
    "            ['公共設施保留地','公設','公保地','公共設施用地','道路用地','溝渠','學校用地'], \n",
    "            ['獨立產權公設','車位併入公設','因公共設施.*與土地所有權人協議價購之案件','公設車位','非道路用地','臨近.*溝渠'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_含地上物之土地\", \n",
    "            ['定著物','地上物','地下物','農作物','工作物','出產物','天然孳息','天然資源','地上農作物','器具','樹','含地上建物','貨櫃屋','地上.*鐵皮屋','含鐵皮屋','地上建物.*未保存登記'], \n",
    "            ['不含地上物'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_向政府機關承購\", \n",
    "            ['承購','水利會','台糖','市府地讓售','跟政府機構購買','國有土地申購','向國防部價購','向國防部標購','公有地'], \n",
    "            ['共有土地承購','水利會協議價購私有土地','水利會價購','水利會協議價購民眾土地'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_含增建或未登記建物\", \n",
    "            ['增建','未.*登記','未.*保存','無保存','未辦保登','無登記','加蓋','外推','加建','外移','頂加','鐵皮屋','鐵皮厝','增建.*農業資材室','增建.*儲藏室'], \n",
    "            ['不包括.*增建','不包括.*未登記','不含.*未登記','未包含.*未保存','無增建','未分割','未.*繼承','補辦登記','未辦理過戶登記','未辦移轉','祖產未登記','未移轉登記','未償債務','不包含未保存','不含未登記','分次登記','未包含在本次土地買賣價金內','地上.*鐵皮屋','含鐵皮屋','未保存建物占用','鄰地.*增建','車位.*面積未登記','尚未成立管委會','抵償','建物.*不計價','不計入價金','未計算價金','未計入土地交易總價中','未辦簽約僅辦理登記','未辦登記僅辦簽約','僅.*產權移轉登記','代理辦理登記','地政士.*並未代理撰擬不動產買賣契約書','無登記在書狀內','不另計價','增建不計價','附贈.*增建','贈與未登記建物','加蓋為0','未辦之借名登記','未登記建物所有權人購買土地','地上未登記建物為買方所有','稅金問題遲未登記','僅受託買賣案件申請登記','增建部分占用國產署土地','未拆分單價'], \n",
    "            ['未辦保存登記及未辦繼承登記','繼承後','未保存建物'])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_親友、員工或其他特殊關係\", \n",
    "            ['親友','朋友','親屬','親戚','近親','員工','特殊關係','關係戶','親等','等親','朋友關係','兄','弟','姐','姊','妹','叔','姪','母','父','女','子','祖','孫','女兒','直系血親','股東','好友','姑','關係人','關係企業','伯','媳','同事','夫','妻','嫂','監察人','董事','婆媳','鄰居間交易','鄰居關係','信徒與寺廟','信徒與宮廟','配偶','姻親','熟人','房東.*房客','承租戶購買','承租戶承買','公益交易','特惠戶','買方為地上房屋所有權人','合夥關係','地主戶'], \n",
    "            ['車位','子母車位','股東股權讓渡','九份子'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_單獨車位\", \n",
    "            ['單獨車位交易','車位買賣','停車塔','機車車位','買賣土地為停車位','車位移轉','單獨出賣.*車位','僅為車位權利範圍移轉','停車位加購','本案僅車位買賣','只買停車位'], \n",
    "            ['內含獨立產權車位','含.*車位','含機車.*位','內含機車位','有機車位','有車位','未各別拆算單一停車位價格','無法拆分','無拆分','無法拆分車位面積','無法拆算','車位拆價','含車位款','車位.*元'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_債權債務影響或債務抵償\", \n",
    "            ['清償','抵償','借','貸','債權','債務','讓與','拍賣','金拍','銀拍','抵押權','攔拍取得'], \n",
    "            ['清償.*費'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_畸零地或有合併使用\", \n",
    "            ['畸零地','崎零地','合併','毗鄰地','毗鄰業主購買','地形調整','地形不整','土地四散','毗鄰界址調整交換分割合併','毗連界址調整交換分割合併'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_協議價購\", \n",
    "            ['協議價購','協購','政府價購','整體開發案價購','交通用地.*價購','一併價購'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_占用相關\", \n",
    "            ['佔用','占用','鑑界','鄰地界指糾葛','占有人','越界','鄰地佔有','房屋現況占鄰地','界址調整','小面積佔有協調','地界線'], \n",
    "            ['第三人[佔占][用有]|他人[佔占][用有]|第三人房屋|他人房屋'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_被他人佔用\", \n",
    "            ['第三人[佔占][用有]|他人[佔占][用有]|第三人房屋|他人房屋'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_急買急賣\", \n",
    "            ['急買','急賣','賣方急錢用','急售','急換屋需資金','急著出售','急出售'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_共有及持分\", \n",
    "            ['共有人.*買賣','土地法34-1','共有人標售','共有人.*交易','共有人承買','共有人承售','持分','共有人買回','民法物權編施行8-5條第3項','共有土地承購','共有物分割後之分割買賣交換合併','產權複雜','共有物買賣','共有人優先承買','共有土地買賣','簡化共有關係'], \n",
    "            ['持分建物','\\d持分','持分\\d','持分調整','整理土地持分','持分共有','共有人數','持分土地','土地產權持分','共有人無人應買'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_所有權人返還\", \n",
    "            ['所有權人返還','借名登記','借名登記返還','返還所有權'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_總價包含費用\", \n",
    "            ['修繕','翻修','有整修','材料變更','管理費','屋況.*翻新','管線*換新','含房屋裝修','屋況有整理過','有裝修','買方補償','全新整理'], \n",
    "            ['賣方.*修繕','不負.*修繕責任','自行修繕'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_價格低於場行情\", \n",
    "            ['公告現值','公告地價','低於市價','賤賣','售價偏低','低於公告市值','產權只移轉一半','優惠','減價','部分價款免除支付','折讓','半買半贈','半捐贈','車位贈送不計價','部份價金免除','特惠價','社區住戶加購價','多戶議價(團購)','團購價','特惠戶','交易總價包含容積移轉價款','照顧住宅','餘戶價售','區段徵收專案配售','總價偏低.*重劃後評定地價及重劃開支狀況訂定標售價格'], \n",
    "            ['客戶要求買賣價金減價，經雙方協議後同意買賣價金不變'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_有民情風俗因素\", \n",
    "            ['民情風俗因素','寺廟','供廟埕使用','路沖','宮廟'], \n",
    "            ['信徒與寺廟間之買賣','信徒與宮廟間之買賣'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_包含權利\", \n",
    "            ['耕作權','通行權','優先承租權','國有地使用權'], \n",
    "            ['無出入通行權'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_未臨路或其餘臨路相關\", \n",
    "            ['無路','無出路','無出口','無產業道路','無聯外','無連外','無適宜連外','未面臨道路','無面臨馬路','未臨道路','未瀕臨巷道','臨路','沒有路','無.*道路','裡地','袋地','道路中斷','車輛無法到達','徒步','死巷','聯外需經他人土地','無通路','無臨接道路'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_土地使用受限\", \n",
    "            ['無法開墾','農路使用','河川','斷層','地質敏感','不易建築','林業區','無意使用','陡','地形歪斜','行水區','不利使用','山坡地保育區','地形崎嶇','無法指定建築線及申請建照','大部分土地沒入河道中','保護區雜木林地'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_鄰地相關\", \n",
    "            ['臨地所有權人購買','鄰地'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_國家機關 國有土地之買賣價格正向影響\", \n",
    "            ['國產署','國有財產署','財產署','國產局','標售','向國產署標購','國有財產承購','市府讓售'], \n",
    "            ['共有人標售','地籍清理.*標售'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_國家機關 國有土地之買賣價格負向影響\", \n",
    "            ['地籍清理','地籍清理.*標售','地清土地','土地清理','祭祀公業'], \n",
    "            ['部分土地係向祭祀公業承租'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_建物含電梯\", \n",
    "            ['電梯','公寓.*電梯','電梯公寓','有裝設電梯'], \n",
    "            ['無電梯'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_其他 價格正向影響\", \n",
    "            ['高價購買','抵費地','抵價地'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_其他 價格負向影響\", \n",
    "            ['地主回購建物','原住名保留地','偏遠','裝修工程款','角地','不動產作價稱資','解除契約','原承租戶','法院調解','工程款減','整批收購','登記簿註記地籍圖計算之面積與登記面積不符','法定空地','分割買賣','分割補償','相互交換','買地送屋','包含未完成建物','部分土地係向祭祀公業承租','拉皮屋','細部計畫尚未完成.*區段徵收整體開發','政府合作開發','車位無產權','買賣標的現有他人占有使用中'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_未辦理繼承登記\", \n",
    "            ['未辦.*繼承','祖產未登記'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_含有租約\", \n",
    "            ['租'], \n",
    "            ['優先承租權','承租戶','承租人','租客承買','三七五租約','375租約','佃農'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_建商與地主之合建案\", \n",
    "            ['合建','土地共同開發關係'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_持分建物\", \n",
    "            ['持分建物'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_包含須注意之增建\", \n",
    "            ['雨遮','雨棚','頂樓','陽台','陽臺','天井','露台','露臺','窗台','凸窗','夾層','防火巷','花台','採光罩','鐵棚'], \n",
    "            ['雨遮.*不予計價','雨遮.*不計價'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_混合使用\", \n",
    "            ['住商混合','營業店面.*住家','工商綜合','店鋪+住宅','一樓.*店面','一樓.*店鋪','1樓.*店面','1樓.*店鋪'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_預售\", \n",
    "            ['預售'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_買回\", \n",
    "            ['買回','原屋主購回'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_其他 不影響價格因素\", \n",
    "            ['旅舍','旅館','攤位','商場舖位','店鋪','倉儲','診所','地下室','工作室','管理組織','管委會','機房','買方另行指定登記名義人','連件辦理','保留戶','信託財產'], \n",
    "            ['另有一儲藏室'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_塔位或墓園\", \n",
    "            ['塔位','墓園','公墓','墳'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_地上權\", \n",
    "            ['地上權'], \n",
    "            ['土地為地上權一部讓與'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_內含獨立產權公設\", \n",
    "            ['獨立產權公設','獨立產權車位','車位併入公設','公設車位'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_內含獨立產權公設\", \n",
    "            ['獨立產權公設','獨立產權車位','車位併入公設','公設車位'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_樣品屋或裝潢\", \n",
    "            ['裝潢','裝璜','實品屋','樣品屋'], \n",
    "            ['重新.*裝潢','翻修裝潢','重新.*裝璜','翻修裝璜'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_建物包含地下室\", \n",
    "            ['地下室'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_其他稅、費相關\", \n",
    "            ['稅','其他費用','整地費','仲介費','賣清','買清'], \n",
    "            ['抵償'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_多戶打通\", \n",
    "            ['打通'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_現況點交\", \n",
    "            ['點交','傢俱','家具','傢具','設備','沙發','電視','床組','冰箱','餐桌','洗衣機','冷氣','現況交付','現況交屋'], \n",
    "            ['無.*設備','不含.*設備','不點交'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_都市計畫農業區建地目土地\", \n",
    "            ['建地目','地目:建'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_訴訟相關\", \n",
    "            ['訴訟買賣案件','法院調解買賣','法院和解','調解購置','訴訟和解','調解買賣'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_耕地三七五\", \n",
    "            ['三七五租約','佃農','375租約'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_建物不計價\", \n",
    "            ['建物不計價'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_車位輪抽\", \n",
    "            ['車位.*抽籤','車位.*輪抽','抽籤.*車位','定期抽籤'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_只買建物\", \n",
    "            ['仁愛之家','土地是仁愛之家所有'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_土地及建物分次登記案件\", \n",
    "            ['分.*次.*登記','土地建物分開登記'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_重劃區土地\", \n",
    "            ['重劃區','土地重劃','區段徵收整體開發'], \n",
    "            ['重劃區抵費地','細部計畫尚未完成.*區段徵收整體開發'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_農舍\", \n",
    "            ['農舍'], \n",
    "            ['不計價','非農舍'], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_私設巷道、道路、通道\", \n",
    "            ['私設道路','私設巷道','私設通道','出入口使用'], \n",
    "            [], \n",
    "            [])\n",
    "\n",
    "set_note_flag(gpd_df_house, \"flag_土地作其他使用\", \n",
    "            ['道路用','道路使用','路地','通行使用','既成道路','現況為道路','既成道路','既成巷道','通道','減災工程','高壓鐵塔用地','通行需要','鐵路用地','電塔用地','水利用地','國土保安用地','園道'], \n",
    "            ['鄰地鐵路管理局管理鐵路用地優先承租權'], \n",
    "            [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd_df_house.to_excel('filter_taipei.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 接下來的資料處理部分在EXCEL中進行處理，分述如下:\n",
    "* 刪除不必要欄位\n",
    "* 確認是否有空值\n",
    "* 檢查實價登陸備註欄\n",
    "* 將部分欄位轉為虛擬變數(Dummy Variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讀入處理後之資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = pd.read_excel('correct_data_x.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = pd.read_excel('correct_data_y.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢視處理後之資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data       土地移轉總面積(平方公尺)  工  住  商  其他  交易筆棟數_土地  交易筆棟數_建物  交易筆棟數_車位      移轉層次  \\\n",
      "0          0.062492  0  1  0   0  0.035714       0.0  0.166667  0.222222   \n",
      "1          0.050186  0  1  0   0  0.071429       0.0  0.083333  0.305556   \n",
      "2          0.044306  0  1  0   0  0.035714       0.0  0.083333  0.194444   \n",
      "3          0.061529  0  0  1   0  0.035714       0.0  0.000000  0.333333   \n",
      "4          0.030439  0  0  1   0  0.035714       0.0  0.000000  0.194444   \n",
      "...             ... .. .. ..  ..       ...       ...       ...       ...   \n",
      "8243       0.198272  0  1  0   0  0.035714       0.0  0.083333  0.138889   \n",
      "8244       0.055884  0  0  1   0  0.071429       0.0  0.083333  0.527778   \n",
      "8245       0.005854  0  0  1   0  0.035714       0.0  0.000000  0.416667   \n",
      "8246       0.169420  0  1  0   0  0.071429       0.0  0.083333  0.444444   \n",
      "8247       0.036189  0  0  1   0  0.071429       0.0  0.083333  0.416667   \n",
      "\n",
      "          總樓層數  ...  其他.1  坡道平面  坡道機械  塔式車位  空格   交易標的橫坐標   交易標的縱坐標        屋齡  \\\n",
      "0     0.354839  ...     0     1     0     0   0  0.577632  0.340208  0.076814   \n",
      "1     0.580645  ...     0     1     0     0   0  0.787067  0.557145  0.349705   \n",
      "2     0.161290  ...     0     0     1     0   0  0.955764  0.571660  0.154290   \n",
      "3     0.161290  ...     0     0     0     0   1  0.786942  0.581006  0.587993   \n",
      "4     0.193548  ...     0     0     0     0   1  0.382630  0.415496  0.312172   \n",
      "...        ...  ...   ...   ...   ...   ...  ..       ...       ...       ...   \n",
      "8243  0.064516  ...     0     1     0     0   0  0.254483  0.946849  0.455022   \n",
      "8244  0.387097  ...     0     0     0     1   0  0.198126  0.907325  0.118175   \n",
      "8245  0.419355  ...     0     0     0     0   1  0.489472  0.069597  0.133822   \n",
      "8246  0.290323  ...     0     1     0     0   0  0.833739  0.522790  0.151075   \n",
      "8247  0.741935  ...     0     1     0     0   0  0.383380  0.262622  0.018577   \n",
      "\n",
      "           lat       lon  \n",
      "0     0.340128  0.576756  \n",
      "1     0.556281  0.787737  \n",
      "2     0.570163  0.956896  \n",
      "3     0.580137  0.787737  \n",
      "4     0.416054  0.381720  \n",
      "...        ...       ...  \n",
      "8243  0.947712  0.255692  \n",
      "8244  0.908371  0.199000  \n",
      "8245  0.069868  0.487123  \n",
      "8246  0.521761  0.834334  \n",
      "8247  0.263206  0.381760  \n",
      "\n",
      "[8248 rows x 46 columns]\n",
      "y_data       單價(元/平方公尺)\n",
      "0         268677\n",
      "1         176252\n",
      "2          98789\n",
      "3         171451\n",
      "4         153983\n",
      "...          ...\n",
      "8243       88643\n",
      "8244      175131\n",
      "8245      175953\n",
      "8246      222855\n",
      "8247      268212\n",
      "\n",
      "[8248 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"x_data\",x_data)\n",
    "print(\"y_data\",y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將資料分成訓練集(佔資料集75%)、測試集(佔資料集25%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢視訓練資料、測試資料\n",
    "* X_train 共 6186 筆資料，包含 64 種變數\n",
    "* y_train 共 6186 筆資料，單位為單價(元/平方公尺)\n",
    "* X_test 共 2062 筆資料，包含 64 種變數\n",
    "* y_test 共 2062 筆資料，單位為單價(元/平方公尺)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train       土地移轉總面積(平方公尺)  工  住  商  其他  交易筆棟數_土地  交易筆棟數_建物  交易筆棟數_車位      移轉層次  \\\n",
      "8124       0.078570  0  0  1   0  0.035714       0.0  0.166667  0.222222   \n",
      "5598       0.042407  0  1  0   0  0.071429       0.0  0.083333  0.222222   \n",
      "7955       0.148034  0  1  0   0  0.035714       0.0  0.083333  0.222222   \n",
      "322        0.027786  0  0  1   0  0.035714       0.0  0.000000  0.361111   \n",
      "7476       0.073731  0  1  0   0  0.035714       0.0  0.000000  0.277778   \n",
      "...             ... .. .. ..  ..       ...       ...       ...       ...   \n",
      "4373       0.109010  0  1  0   0  0.035714       0.0  0.000000  0.277778   \n",
      "7891       0.040534  0  0  1   0  0.035714       0.0  0.000000  0.305556   \n",
      "4859       0.105263  0  1  0   0  0.035714       0.0  0.083333  0.388889   \n",
      "3264       0.098733  0  1  0   0  0.035714       0.0  0.166667  0.277778   \n",
      "2732       0.082525  0  1  0   0  0.035714       0.0  0.083333  0.333333   \n",
      "\n",
      "          總樓層數  ...  其他.1  坡道平面  坡道機械  塔式車位  空格   交易標的橫坐標   交易標的縱坐標        屋齡  \\\n",
      "8124  0.387097  ...     0     1     0     0   0  0.793502  0.532554  0.035074   \n",
      "5598  0.290323  ...     0     1     0     0   0  0.783505  0.549731  0.316095   \n",
      "7955  0.096774  ...     0     1     0     0   0  0.759388  0.051480  0.045710   \n",
      "322   0.322581  ...     0     0     0     0   1  0.436551  0.276406  0.504751   \n",
      "7476  0.096774  ...     0     0     0     0   1  0.520587  0.617762  0.629497   \n",
      "...        ...  ...   ...   ...   ...   ...  ..       ...       ...       ...   \n",
      "4373  0.129032  ...     0     0     0     0   1  0.465917  0.376495  0.781565   \n",
      "7891  0.193548  ...     0     0     0     0   1  0.254670  0.396074  0.509241   \n",
      "4859  0.387097  ...     0     1     0     0   0  0.242299  0.291182  0.076719   \n",
      "3264  0.548387  ...     0     1     0     0   0  0.677288  0.231348  0.113307   \n",
      "2732  0.193548  ...     0     1     0     0   0  0.228491  0.368297  0.302245   \n",
      "\n",
      "           lat       lon  \n",
      "8124  0.531671  0.794058  \n",
      "5598  0.548881  0.784129  \n",
      "7955  0.050816  0.757374  \n",
      "322   0.276813  0.435095  \n",
      "7476  0.617823  0.520947  \n",
      "...        ...       ...  \n",
      "4373  0.376785  0.464994  \n",
      "7891  0.397042  0.253407  \n",
      "4859  0.292208  0.240542  \n",
      "3264  0.230942  0.676057  \n",
      "2732  0.369352  0.227050  \n",
      "\n",
      "[6186 rows x 46 columns]\n",
      "y_train       單價(元/平方公尺)\n",
      "8124      172423\n",
      "5598      135630\n",
      "7955      142100\n",
      "322       243195\n",
      "7476      184831\n",
      "...          ...\n",
      "4373      250548\n",
      "7891      151267\n",
      "4859      130409\n",
      "3264      163821\n",
      "2732      108631\n",
      "\n",
      "[6186 rows x 1 columns]\n",
      "X_test       土地移轉總面積(平方公尺)  工  住  商  其他  交易筆棟數_土地  交易筆棟數_建物  交易筆棟數_車位      移轉層次  \\\n",
      "509        0.038427  0  0  1   0  0.035714  0.000000  0.000000  0.361111   \n",
      "7822       0.014934  0  0  1   0  0.035714  0.111111  0.000000  0.500000   \n",
      "6157       0.061711  0  1  0   0  0.071429  0.000000  0.000000  0.166667   \n",
      "5284       0.029555  0  0  0   1  0.035714  0.000000  0.083333  0.333333   \n",
      "1666       0.006218  0  0  1   0  0.035714  0.000000  0.000000  0.500000   \n",
      "...             ... .. .. ..  ..       ...       ...       ...       ...   \n",
      "3753       0.030179  0  0  1   0  0.035714  0.000000  0.000000  0.388889   \n",
      "4422       0.080391  0  1  0   0  0.035714  0.000000  0.000000  0.222222   \n",
      "6108       0.055155  0  0  1   0  0.035714  0.000000  0.000000  0.611111   \n",
      "6414       0.068085  0  0  1   0  0.035714  0.000000  0.000000  0.305556   \n",
      "6519       0.009652  0  0  1   0  0.035714  0.000000  0.000000  0.250000   \n",
      "\n",
      "          總樓層數  ...  其他.1  坡道平面  坡道機械  塔式車位  空格   交易標的橫坐標   交易標的縱坐標        屋齡  \\\n",
      "509   0.225806  ...     0     0     0     0   1  0.279350  0.641571  0.007989   \n",
      "7822  0.516129  ...     0     0     0     0   1  0.501343  0.082285  0.390782   \n",
      "6157  0.096774  ...     0     0     0     0   1  0.260981  0.877147  0.022453   \n",
      "5284  0.193548  ...     0     0     0     0   0  0.257919  0.911345  0.295628   \n",
      "1666  0.419355  ...     0     0     0     0   1  0.379694  0.420561  0.127724   \n",
      "...        ...  ...   ...   ...   ...   ...  ..       ...       ...       ...   \n",
      "3753  0.451613  ...     0     0     0     0   1  0.798625  0.603665  0.463484   \n",
      "4422  0.064516  ...     0     0     0     0   1  0.610309  0.294210  0.719499   \n",
      "6108  0.548387  ...     0     0     0     0   1  0.327898  0.445883  0.258473   \n",
      "6414  0.161290  ...     0     0     0     0   1  0.310715  0.549522  0.552257   \n",
      "6519  0.451613  ...     0     0     0     0   1  0.622743  0.466037  0.574143   \n",
      "\n",
      "           lat       lon  \n",
      "509   0.642415  0.279247  \n",
      "7822  0.082513  0.499074  \n",
      "6157  0.878003  0.261895  \n",
      "5284  0.912204  0.258978  \n",
      "1666  0.421127  0.378801  \n",
      "...        ...       ...  \n",
      "3753  0.602749  0.799566  \n",
      "4422  0.294026  0.609269  \n",
      "6108  0.446611  0.327013  \n",
      "6414  0.550285  0.310267  \n",
      "6519  0.465776  0.622585  \n",
      "\n",
      "[2062 rows x 46 columns]\n",
      "y_test       單價(元/平方公尺)\n",
      "509       160495\n",
      "7822      151249\n",
      "6157      168581\n",
      "5284      120916\n",
      "1666      203088\n",
      "...          ...\n",
      "3753      184957\n",
      "4422      163783\n",
      "6108      216649\n",
      "6414      126713\n",
      "6519      208555\n",
      "\n",
      "[2062 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train\",X_train)\n",
    "print(\"y_train\",y_train)\n",
    "print(\"X_test\",X_test)\n",
    "print(\"y_test\",y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Flatten, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建置不動產估價模型AVM(Automatic Valuation Models)\n",
    "* 隱藏層數 = 2\n",
    "* 激活函數 = LeakyReLU(alpha=0.22)\n",
    "* Dropout 層 = 1\n",
    "* 損失函數 = MAPE\n",
    "* 優化器 = ADAM\n",
    "* 在第一個隱藏層與激活函數間建立BN層(BatchNormalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512,input_dim=46))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation(tf.keras.layers.LeakyReLU(alpha=0.22)))\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(tf.keras.layers.LeakyReLU(alpha=0.22)))\n",
    "model.add(Dropout(0.175))\n",
    "# model.add(Dense(128))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(tf.keras.layers.LeakyReLU(alpha=0.22)))\n",
    "# model.add(Dropout(0.235))\n",
    "model.add(Dense(64))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation(tf.keras.layers.LeakyReLU(alpha=0.22)))\n",
    "model.add(Dense(1,activation=tf.keras.layers.LeakyReLU(alpha=0.22)))\n",
    "model.compile(loss='mean_absolute_percentage_error',optimizer='Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢視模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 512)               24064     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 172,929\n",
      "Trainable params: 172,417\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 為了避免繼續訓練模型會導致測試集上的準確率下降(或是說loss上升)，我們引入了EarlyStopping提前停止訓練，當驗證集loss的減少程度不再下降時則停止繼續訓練\n",
    "\n",
    "* monitor設為'val_loss'，用以監控驗證集的loss\n",
    "* patience設為50，若經過50次epochs後驗證集的loss不再顯著下降，則提前停止訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 70, verbose = 1, mode = 'auto') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將訓練集27.5%分割為驗證集，開始訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 99.9964 - val_loss: 99.9990\n",
      "Epoch 2/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 99.9885 - val_loss: 99.9973\n",
      "Epoch 3/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 99.9755 - val_loss: 99.9947\n",
      "Epoch 4/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 99.9543 - val_loss: 99.9834\n",
      "Epoch 5/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 99.9232 - val_loss: 99.9639\n",
      "Epoch 6/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 99.8818 - val_loss: 99.9285\n",
      "Epoch 7/700\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 99.8269 - val_loss: 99.8809\n",
      "Epoch 8/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 99.7577 - val_loss: 99.8165\n",
      "Epoch 9/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 99.6703 - val_loss: 99.6822\n",
      "Epoch 10/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 99.5548 - val_loss: 99.5330\n",
      "Epoch 11/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 99.4151 - val_loss: 99.3791\n",
      "Epoch 12/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 99.2438 - val_loss: 99.0965\n",
      "Epoch 13/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 99.0319 - val_loss: 98.6136\n",
      "Epoch 14/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 98.7692 - val_loss: 98.1812\n",
      "Epoch 15/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 98.4892 - val_loss: 97.7923\n",
      "Epoch 16/700\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 98.1769 - val_loss: 97.6320\n",
      "Epoch 17/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 97.8206 - val_loss: 97.3177\n",
      "Epoch 18/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 97.4278 - val_loss: 96.8025\n",
      "Epoch 19/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 96.9832 - val_loss: 96.3682\n",
      "Epoch 20/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 96.5007 - val_loss: 95.6827\n",
      "Epoch 21/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 95.9816 - val_loss: 95.1696\n",
      "Epoch 22/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 95.3953 - val_loss: 94.3441\n",
      "Epoch 23/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 94.7607 - val_loss: 94.1493\n",
      "Epoch 24/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 94.0786 - val_loss: 93.4670\n",
      "Epoch 25/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 93.3490 - val_loss: 91.9264\n",
      "Epoch 26/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 92.5438 - val_loss: 91.8919\n",
      "Epoch 27/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 91.6782 - val_loss: 91.2387\n",
      "Epoch 28/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 90.7548 - val_loss: 90.8555\n",
      "Epoch 29/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 89.7813 - val_loss: 88.6422\n",
      "Epoch 30/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 88.7281 - val_loss: 88.0542\n",
      "Epoch 31/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 87.6453 - val_loss: 86.7299\n",
      "Epoch 32/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 86.4704 - val_loss: 85.8809\n",
      "Epoch 33/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 85.2129 - val_loss: 84.8026\n",
      "Epoch 34/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 83.8838 - val_loss: 83.3869\n",
      "Epoch 35/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 82.5226 - val_loss: 82.3907\n",
      "Epoch 36/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 81.0470 - val_loss: 81.2249\n",
      "Epoch 37/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 79.5383 - val_loss: 77.0901\n",
      "Epoch 38/700\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 77.9390 - val_loss: 76.5079\n",
      "Epoch 39/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 76.2985 - val_loss: 74.7218\n",
      "Epoch 40/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 74.6128 - val_loss: 71.5340\n",
      "Epoch 41/700\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 72.8918 - val_loss: 69.6795\n",
      "Epoch 42/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 71.1754 - val_loss: 67.2954\n",
      "Epoch 43/700\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 69.2951 - val_loss: 64.6018\n",
      "Epoch 44/700\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 67.4929 - val_loss: 64.5962\n",
      "Epoch 45/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 65.6294 - val_loss: 63.0873\n",
      "Epoch 46/700\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 63.7495 - val_loss: 63.2745\n",
      "Epoch 47/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 61.9840 - val_loss: 59.0524\n",
      "Epoch 48/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 59.9660 - val_loss: 57.1307\n",
      "Epoch 49/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 58.0888 - val_loss: 57.0489\n",
      "Epoch 50/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 56.3110 - val_loss: 51.0292\n",
      "Epoch 51/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 54.4170 - val_loss: 48.3503\n",
      "Epoch 52/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 52.5816 - val_loss: 48.2887\n",
      "Epoch 53/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 50.4883 - val_loss: 44.9241\n",
      "Epoch 54/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 48.1865 - val_loss: 38.6018\n",
      "Epoch 55/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 46.0065 - val_loss: 37.4129\n",
      "Epoch 56/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 44.0063 - val_loss: 36.4509\n",
      "Epoch 57/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 42.2749 - val_loss: 35.1877\n",
      "Epoch 58/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 40.6122 - val_loss: 35.3066\n",
      "Epoch 59/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 39.4104 - val_loss: 34.8319\n",
      "Epoch 60/700\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 38.2958 - val_loss: 34.1017\n",
      "Epoch 61/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 37.5778 - val_loss: 34.5967\n",
      "Epoch 62/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 36.8262 - val_loss: 33.6690\n",
      "Epoch 63/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 36.1395 - val_loss: 33.3077\n",
      "Epoch 64/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 35.9538 - val_loss: 33.2974\n",
      "Epoch 65/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 35.4020 - val_loss: 32.9961\n",
      "Epoch 66/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 35.0510 - val_loss: 32.7688\n",
      "Epoch 67/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 34.8291 - val_loss: 33.8096\n",
      "Epoch 68/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 34.8329 - val_loss: 32.5503\n",
      "Epoch 69/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 34.7321 - val_loss: 32.6104\n",
      "Epoch 70/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 34.4422 - val_loss: 32.4197\n",
      "Epoch 71/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 34.2586 - val_loss: 32.1815\n",
      "Epoch 72/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 33.8835 - val_loss: 32.2633\n",
      "Epoch 73/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 33.7641 - val_loss: 31.9570\n",
      "Epoch 74/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 33.6137 - val_loss: 32.8413\n",
      "Epoch 75/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 33.9043 - val_loss: 31.9607\n",
      "Epoch 76/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 33.7743 - val_loss: 32.2890\n",
      "Epoch 77/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 33.8069 - val_loss: 32.2450\n",
      "Epoch 78/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 33.4954 - val_loss: 33.6346\n",
      "Epoch 79/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 34.0250 - val_loss: 31.7094\n",
      "Epoch 80/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 33.2308 - val_loss: 31.5261\n",
      "Epoch 81/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 9ms/step - loss: 33.1671 - val_loss: 31.3158\n",
      "Epoch 82/700\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 33.0106 - val_loss: 31.9100\n",
      "Epoch 83/700\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 33.3092 - val_loss: 31.7855\n",
      "Epoch 84/700\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 33.0416 - val_loss: 31.2418\n",
      "Epoch 85/700\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 32.9020 - val_loss: 31.4754\n",
      "Epoch 86/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 33.0189 - val_loss: 31.6027\n",
      "Epoch 87/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 32.8700 - val_loss: 31.4651\n",
      "Epoch 88/700\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 32.8799 - val_loss: 31.7422\n",
      "Epoch 89/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 32.8046 - val_loss: 31.5439\n",
      "Epoch 90/700\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 32.5182 - val_loss: 30.2328\n",
      "Epoch 91/700\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 31.1672 - val_loss: 29.8023\n",
      "Epoch 92/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 30.7380 - val_loss: 31.3431\n",
      "Epoch 93/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 30.4963 - val_loss: 29.4408\n",
      "Epoch 94/700\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 30.3145 - val_loss: 29.9020\n",
      "Epoch 95/700\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 30.1638 - val_loss: 30.0550\n",
      "Epoch 96/700\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 30.4424 - val_loss: 29.9017\n",
      "Epoch 97/700\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 30.1669 - val_loss: 29.3368\n",
      "Epoch 98/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 29.9573 - val_loss: 30.1773\n",
      "Epoch 99/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 30.1696 - val_loss: 29.6504\n",
      "Epoch 100/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 30.0454 - val_loss: 29.3841\n",
      "Epoch 101/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 29.7706 - val_loss: 29.7403\n",
      "Epoch 102/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 29.5889 - val_loss: 29.3912\n",
      "Epoch 103/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 29.5448 - val_loss: 29.6731\n",
      "Epoch 104/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 29.7557 - val_loss: 30.4723\n",
      "Epoch 105/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 29.6812 - val_loss: 29.4401\n",
      "Epoch 106/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 29.6284 - val_loss: 29.0444\n",
      "Epoch 107/700\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 29.3861 - val_loss: 28.7359\n",
      "Epoch 108/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 29.2457 - val_loss: 29.1758\n",
      "Epoch 109/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 29.5782 - val_loss: 29.1679\n",
      "Epoch 110/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 28.9802 - val_loss: 28.1809\n",
      "Epoch 111/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 28.7413 - val_loss: 26.5643\n",
      "Epoch 112/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 28.1828 - val_loss: 25.2216\n",
      "Epoch 113/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 27.1824 - val_loss: 22.8813\n",
      "Epoch 114/700\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 25.6175 - val_loss: 21.1853\n",
      "Epoch 115/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 24.3842 - val_loss: 19.1381\n",
      "Epoch 116/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 23.1954 - val_loss: 18.8025\n",
      "Epoch 117/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 21.4356 - val_loss: 17.9233\n",
      "Epoch 118/700\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 19.6411 - val_loss: 19.0732\n",
      "Epoch 119/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 18.1282 - val_loss: 19.5578\n",
      "Epoch 120/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 17.2183 - val_loss: 17.8337\n",
      "Epoch 121/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 16.8650 - val_loss: 17.5856\n",
      "Epoch 122/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 16.6532 - val_loss: 17.8327\n",
      "Epoch 123/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 16.2569 - val_loss: 16.9909\n",
      "Epoch 124/700\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 15.6713 - val_loss: 16.6943\n",
      "Epoch 125/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 15.5068 - val_loss: 16.1500\n",
      "Epoch 126/700\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 15.3639 - val_loss: 15.9252\n",
      "Epoch 127/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 15.2453 - val_loss: 15.7534\n",
      "Epoch 128/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 14.8516 - val_loss: 15.0869\n",
      "Epoch 129/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 14.5095 - val_loss: 14.9546\n",
      "Epoch 130/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 14.2339 - val_loss: 14.9347\n",
      "Epoch 131/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 14.0857 - val_loss: 15.0240\n",
      "Epoch 132/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 14.0600 - val_loss: 14.8461\n",
      "Epoch 133/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 13.9258 - val_loss: 14.8420\n",
      "Epoch 134/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 13.9032 - val_loss: 14.9160\n",
      "Epoch 135/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 13.7593 - val_loss: 15.4926\n",
      "Epoch 136/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 13.6336 - val_loss: 15.0516\n",
      "Epoch 137/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 13.7327 - val_loss: 15.4289\n",
      "Epoch 138/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 13.7639 - val_loss: 15.6152\n",
      "Epoch 139/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 13.7760 - val_loss: 15.4284\n",
      "Epoch 140/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 13.4580 - val_loss: 15.1422\n",
      "Epoch 141/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 13.3869 - val_loss: 15.6508\n",
      "Epoch 142/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 13.3848 - val_loss: 14.6338\n",
      "Epoch 143/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 13.4618 - val_loss: 14.7723\n",
      "Epoch 144/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 13.3469 - val_loss: 14.9543\n",
      "Epoch 145/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 13.3277 - val_loss: 15.7243\n",
      "Epoch 146/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 13.1634 - val_loss: 15.0391\n",
      "Epoch 147/700\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 12.9969 - val_loss: 14.8870\n",
      "Epoch 148/700\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 13.0954 - val_loss: 15.2714\n",
      "Epoch 149/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 13.1865 - val_loss: 14.9016\n",
      "Epoch 150/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 13.1330 - val_loss: 14.5035\n",
      "Epoch 151/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 13.0632 - val_loss: 14.7323\n",
      "Epoch 152/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 13.1844 - val_loss: 14.8401\n",
      "Epoch 153/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 13.0141 - val_loss: 14.9645\n",
      "Epoch 154/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 12.8880 - val_loss: 14.7086\n",
      "Epoch 155/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 12.9873 - val_loss: 14.2243\n",
      "Epoch 156/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 12.8969 - val_loss: 14.8829\n",
      "Epoch 157/700\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 13.0065 - val_loss: 16.1835\n",
      "Epoch 158/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 12.5664 - val_loss: 14.1173\n",
      "Epoch 159/700\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 12.6610 - val_loss: 14.4585\n",
      "Epoch 160/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 12ms/step - loss: 12.8998 - val_loss: 14.4038\n",
      "Epoch 161/700\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 12.7693 - val_loss: 14.4208\n",
      "Epoch 162/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 12.8449 - val_loss: 14.6459\n",
      "Epoch 163/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 12.8935 - val_loss: 14.0245\n",
      "Epoch 164/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 12.6955 - val_loss: 14.1327\n",
      "Epoch 165/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 12.7864 - val_loss: 14.4908\n",
      "Epoch 166/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 12.5410 - val_loss: 14.2609\n",
      "Epoch 167/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 12.6030 - val_loss: 14.3568\n",
      "Epoch 168/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 12.4986 - val_loss: 14.1090\n",
      "Epoch 169/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 12.3906 - val_loss: 14.2741\n",
      "Epoch 170/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 12.4864 - val_loss: 14.2538\n",
      "Epoch 171/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 12.4412 - val_loss: 15.1342\n",
      "Epoch 172/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 12.4189 - val_loss: 14.9959\n",
      "Epoch 173/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 12.7119 - val_loss: 15.3825\n",
      "Epoch 174/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 12.3579 - val_loss: 14.3169\n",
      "Epoch 175/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 12.3936 - val_loss: 14.6713\n",
      "Epoch 176/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 12.5043 - val_loss: 14.6050\n",
      "Epoch 177/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.5078 - val_loss: 14.5375\n",
      "Epoch 178/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 12.5754 - val_loss: 13.9372\n",
      "Epoch 179/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 12.3516 - val_loss: 13.9626\n",
      "Epoch 180/700\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 12.2636 - val_loss: 14.1449\n",
      "Epoch 181/700\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 12.3863 - val_loss: 14.0544\n",
      "Epoch 182/700\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 12.1387 - val_loss: 13.9761\n",
      "Epoch 183/700\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 12.4205 - val_loss: 14.7851\n",
      "Epoch 184/700\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 12.1778 - val_loss: 13.9463\n",
      "Epoch 185/700\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 12.1552 - val_loss: 15.8197\n",
      "Epoch 186/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 12.7017 - val_loss: 13.9641\n",
      "Epoch 187/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 12.1189 - val_loss: 13.7589\n",
      "Epoch 188/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 11.9597 - val_loss: 15.0724\n",
      "Epoch 189/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 12.0613 - val_loss: 13.9576\n",
      "Epoch 190/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 12.0221 - val_loss: 14.3302\n",
      "Epoch 191/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 12.6532 - val_loss: 16.1862\n",
      "Epoch 192/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 12.5229 - val_loss: 13.9646\n",
      "Epoch 193/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 12.1284 - val_loss: 14.2461\n",
      "Epoch 194/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9519 - val_loss: 14.5930\n",
      "Epoch 195/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9931 - val_loss: 13.6757\n",
      "Epoch 196/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.9990 - val_loss: 14.0227\n",
      "Epoch 197/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.1371 - val_loss: 14.0100\n",
      "Epoch 198/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.1115 - val_loss: 14.2051\n",
      "Epoch 199/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0176 - val_loss: 14.3153\n",
      "Epoch 200/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8988 - val_loss: 13.7385\n",
      "Epoch 201/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.0699 - val_loss: 14.4322\n",
      "Epoch 202/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8392 - val_loss: 13.7022\n",
      "Epoch 203/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.7392 - val_loss: 14.3247\n",
      "Epoch 204/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.8741 - val_loss: 13.6582\n",
      "Epoch 205/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.6688 - val_loss: 15.1240\n",
      "Epoch 206/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.9711 - val_loss: 13.9074\n",
      "Epoch 207/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 12.0423 - val_loss: 14.3885\n",
      "Epoch 208/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 12.1469 - val_loss: 13.7310\n",
      "Epoch 209/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 11.8573 - val_loss: 13.7491\n",
      "Epoch 210/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.6281 - val_loss: 14.4372\n",
      "Epoch 211/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.8912 - val_loss: 13.6454\n",
      "Epoch 212/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.8129 - val_loss: 13.7736\n",
      "Epoch 213/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.8778 - val_loss: 13.9452\n",
      "Epoch 214/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 11.7551 - val_loss: 13.9055\n",
      "Epoch 215/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.7127 - val_loss: 13.8091\n",
      "Epoch 216/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.9302 - val_loss: 14.2173\n",
      "Epoch 217/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.9661 - val_loss: 17.2042\n",
      "Epoch 218/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 12.0249 - val_loss: 13.7772\n",
      "Epoch 219/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 11.5109 - val_loss: 13.9941\n",
      "Epoch 220/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.6419 - val_loss: 13.9761\n",
      "Epoch 221/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 11.5261 - val_loss: 14.8002\n",
      "Epoch 222/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 11.7330 - val_loss: 14.5214\n",
      "Epoch 223/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 11.8291 - val_loss: 14.0056\n",
      "Epoch 224/700\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 11.6686 - val_loss: 14.0331\n",
      "Epoch 225/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.4548 - val_loss: 13.7005\n",
      "Epoch 226/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 11.5335 - val_loss: 13.7605\n",
      "Epoch 227/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.3984 - val_loss: 14.2417\n",
      "Epoch 228/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 11.4795 - val_loss: 13.9144\n",
      "Epoch 229/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 11.7084 - val_loss: 13.7510\n",
      "Epoch 230/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 11.5510 - val_loss: 13.5230\n",
      "Epoch 231/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.5721 - val_loss: 13.5839\n",
      "Epoch 232/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.5179 - val_loss: 13.8819\n",
      "Epoch 233/700\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 11.5622 - val_loss: 13.6550\n",
      "Epoch 234/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 11.4063 - val_loss: 14.6449\n",
      "Epoch 235/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.3879 - val_loss: 13.9015\n",
      "Epoch 236/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.3180 - val_loss: 13.5281\n",
      "Epoch 237/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 11.3999 - val_loss: 14.0532\n",
      "Epoch 238/700\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 11.4272 - val_loss: 14.7106\n",
      "Epoch 239/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 10ms/step - loss: 11.4394 - val_loss: 13.6475\n",
      "Epoch 240/700\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 11.4988 - val_loss: 13.6295\n",
      "Epoch 241/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 11.8771 - val_loss: 13.9479\n",
      "Epoch 242/700\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 11.7208 - val_loss: 13.6592\n",
      "Epoch 243/700\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 11.3756 - val_loss: 14.1535\n",
      "Epoch 244/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 11.5355 - val_loss: 14.4371\n",
      "Epoch 245/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 11.6260 - val_loss: 13.8484\n",
      "Epoch 246/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.3203 - val_loss: 14.2361\n",
      "Epoch 247/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.3732 - val_loss: 13.6342\n",
      "Epoch 248/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 11.2302 - val_loss: 14.1629\n",
      "Epoch 249/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.3197 - val_loss: 15.5667\n",
      "Epoch 250/700\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 11.4179 - val_loss: 13.6890\n",
      "Epoch 251/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 11.2635 - val_loss: 13.8879\n",
      "Epoch 252/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.4824 - val_loss: 14.2316\n",
      "Epoch 253/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.4228 - val_loss: 14.8858\n",
      "Epoch 254/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.4658 - val_loss: 13.8286\n",
      "Epoch 255/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.3512 - val_loss: 14.3523\n",
      "Epoch 256/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.4576 - val_loss: 13.6706\n",
      "Epoch 257/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.2474 - val_loss: 14.0439\n",
      "Epoch 258/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.3196 - val_loss: 13.7438\n",
      "Epoch 259/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.2208 - val_loss: 14.2498\n",
      "Epoch 260/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 11.1862 - val_loss: 13.5149\n",
      "Epoch 261/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.0284 - val_loss: 13.7455\n",
      "Epoch 262/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.0569 - val_loss: 13.7881\n",
      "Epoch 263/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.2786 - val_loss: 14.3416\n",
      "Epoch 264/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 11.3875 - val_loss: 13.9391\n",
      "Epoch 265/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.2720 - val_loss: 14.9509\n",
      "Epoch 266/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 11.1472 - val_loss: 13.8281\n",
      "Epoch 267/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.0642 - val_loss: 14.4405\n",
      "Epoch 268/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.9659 - val_loss: 13.6062\n",
      "Epoch 269/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.9996 - val_loss: 13.9153\n",
      "Epoch 270/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 11.1268 - val_loss: 14.3078\n",
      "Epoch 271/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 11.1607 - val_loss: 13.8137\n",
      "Epoch 272/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.3407 - val_loss: 14.3440\n",
      "Epoch 273/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 10.9491 - val_loss: 13.5001\n",
      "Epoch 274/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.0073 - val_loss: 13.7385\n",
      "Epoch 275/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.0212 - val_loss: 13.6854\n",
      "Epoch 276/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 11.1547 - val_loss: 13.5909\n",
      "Epoch 277/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.0408 - val_loss: 13.5257\n",
      "Epoch 278/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.0734 - val_loss: 13.9921\n",
      "Epoch 279/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 11.3519 - val_loss: 14.3613\n",
      "Epoch 280/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 11.1173 - val_loss: 13.5185\n",
      "Epoch 281/700\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 11.0142 - val_loss: 13.8921\n",
      "Epoch 282/700\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 10.9506 - val_loss: 13.9958\n",
      "Epoch 283/700\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 11.2373 - val_loss: 14.8636\n",
      "Epoch 284/700\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 11.2703 - val_loss: 13.6765\n",
      "Epoch 285/700\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 11.1714 - val_loss: 14.0694\n",
      "Epoch 286/700\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 11.2272 - val_loss: 14.2574\n",
      "Epoch 287/700\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 10.9926 - val_loss: 14.0958\n",
      "Epoch 288/700\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 11.2954 - val_loss: 14.0530\n",
      "Epoch 289/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 10.9220 - val_loss: 13.9737\n",
      "Epoch 290/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.8423 - val_loss: 13.7891\n",
      "Epoch 291/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 10.8722 - val_loss: 13.5537\n",
      "Epoch 292/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 10.8181 - val_loss: 15.2784\n",
      "Epoch 293/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.9745 - val_loss: 13.8879\n",
      "Epoch 294/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.0202 - val_loss: 13.5695\n",
      "Epoch 295/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 10.9183 - val_loss: 15.4596\n",
      "Epoch 296/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 10.8563 - val_loss: 13.3859\n",
      "Epoch 297/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.9369 - val_loss: 14.6440\n",
      "Epoch 298/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 11.1364 - val_loss: 14.4483\n",
      "Epoch 299/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.8920 - val_loss: 14.0729\n",
      "Epoch 300/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 10.9699 - val_loss: 13.6366\n",
      "Epoch 301/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.8856 - val_loss: 14.1613\n",
      "Epoch 302/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 11.0431 - val_loss: 13.9291\n",
      "Epoch 303/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.9497 - val_loss: 13.7942\n",
      "Epoch 304/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.7890 - val_loss: 13.8250\n",
      "Epoch 305/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 10.8791 - val_loss: 13.6677\n",
      "Epoch 306/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 10.8129 - val_loss: 14.1348\n",
      "Epoch 307/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.8241 - val_loss: 14.0680\n",
      "Epoch 308/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 11.0855 - val_loss: 14.1580\n",
      "Epoch 309/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.9110 - val_loss: 13.8008\n",
      "Epoch 310/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.8898 - val_loss: 13.7048\n",
      "Epoch 311/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.8677 - val_loss: 13.7884\n",
      "Epoch 312/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.7019 - val_loss: 13.5975\n",
      "Epoch 313/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.8117 - val_loss: 13.6036\n",
      "Epoch 314/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.8138 - val_loss: 13.6453\n",
      "Epoch 315/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 10.9627 - val_loss: 13.8795\n",
      "Epoch 316/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.6855 - val_loss: 13.9600\n",
      "Epoch 317/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.7895 - val_loss: 14.0430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 11.0553 - val_loss: 15.2525\n",
      "Epoch 319/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 10.9802 - val_loss: 13.6840\n",
      "Epoch 320/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 10.7282 - val_loss: 14.8435\n",
      "Epoch 321/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.6515 - val_loss: 13.5981\n",
      "Epoch 322/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.8635 - val_loss: 14.1714\n",
      "Epoch 323/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 10.7642 - val_loss: 13.6649\n",
      "Epoch 324/700\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 10.6397 - val_loss: 14.1881\n",
      "Epoch 325/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 10.8879 - val_loss: 13.7185\n",
      "Epoch 326/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 10.8043 - val_loss: 14.1735\n",
      "Epoch 327/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.5981 - val_loss: 13.6293\n",
      "Epoch 328/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 10.9148 - val_loss: 13.9777\n",
      "Epoch 329/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.7537 - val_loss: 13.4884\n",
      "Epoch 330/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 10.7623 - val_loss: 14.1036\n",
      "Epoch 331/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 10.9029 - val_loss: 14.0977\n",
      "Epoch 332/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 10.6913 - val_loss: 13.5965\n",
      "Epoch 333/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 10.7247 - val_loss: 13.6804\n",
      "Epoch 334/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.7040 - val_loss: 13.8441\n",
      "Epoch 335/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 10.6063 - val_loss: 13.4475\n",
      "Epoch 336/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.6553 - val_loss: 13.6388\n",
      "Epoch 337/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 10.7865 - val_loss: 14.0782\n",
      "Epoch 338/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.6744 - val_loss: 14.2716\n",
      "Epoch 339/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 10.6117 - val_loss: 13.6907\n",
      "Epoch 340/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 10.8799 - val_loss: 13.6671\n",
      "Epoch 341/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 10.8412 - val_loss: 13.7935\n",
      "Epoch 342/700\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 10.5797 - val_loss: 13.7235\n",
      "Epoch 343/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 10.6372 - val_loss: 14.2576\n",
      "Epoch 344/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 10.5445 - val_loss: 13.4534\n",
      "Epoch 345/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 10.6337 - val_loss: 13.8845\n",
      "Epoch 346/700\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 11.0112 - val_loss: 13.6829\n",
      "Epoch 347/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 10.7270 - val_loss: 15.1202\n",
      "Epoch 348/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 10.6988 - val_loss: 14.1260\n",
      "Epoch 349/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 10.7974 - val_loss: 13.9963\n",
      "Epoch 350/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 10.6270 - val_loss: 14.0321\n",
      "Epoch 351/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 10.4667 - val_loss: 13.8035\n",
      "Epoch 352/700\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 10.4583 - val_loss: 13.7016\n",
      "Epoch 353/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 10.6735 - val_loss: 13.6043\n",
      "Epoch 354/700\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 10.5826 - val_loss: 13.4345\n",
      "Epoch 355/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 10.7667 - val_loss: 14.2928\n",
      "Epoch 356/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 10.6419 - val_loss: 13.9114\n",
      "Epoch 357/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 10.4969 - val_loss: 14.0788\n",
      "Epoch 358/700\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 10.8539 - val_loss: 14.3491\n",
      "Epoch 359/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 10.5147 - val_loss: 13.9793\n",
      "Epoch 360/700\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 10.8000 - val_loss: 13.9216\n",
      "Epoch 361/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 10.8156 - val_loss: 14.1659\n",
      "Epoch 362/700\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 10.5881 - val_loss: 13.6339\n",
      "Epoch 363/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 10.5306 - val_loss: 13.5798\n",
      "Epoch 364/700\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 10.5914 - val_loss: 15.0298\n",
      "Epoch 365/700\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 10.7557 - val_loss: 13.9324\n",
      "Epoch 366/700\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 10.4756 - val_loss: 13.7042\n",
      "Epoch 00366: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,batch_size=256,epochs=700,validation_split = 0.275,callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以模型預測測試集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2062"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(X_test)\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPE : \n",
    "* AVM模型測試標準通常以平均絕對誤差百分比（MAPE）及命中率（Hit Rate）這兩項作為判定模型好壞的評估指標。\n",
    "\n",
    "* MAPE為大量不動產估價之平均誤差值，計算方式為衡量估計值與實際成交價間之差異程度後，取其絕對誤差的平均值，而MAPE數值愈小表示模型估計愈精準。\n",
    "\n",
    "* 實務研究中，MAPE以小於15%為標準，而本研究模型之MAPE達13.6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.646167334459165"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAPE(y_test,result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看訓練集與驗證集的loss\n",
    "* 可見模型訓練後期逐漸收斂，訓練集與驗證集的MAPE不再有明顯改變，於epoch=366時提前停止訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hit Rate :\n",
    "* 命中率表示有多少比例的不動產估值誤差低於某一誤差水準值，命中率愈高代表模型表現愈好。\n",
    "\n",
    "* 舉例說明，誤差在10%內的命中率為80%，代表在100筆資料中，有80筆資料估計的誤差範圍落在10%以內，剩餘的20筆資料是估計誤差大於10%。\n",
    "\n",
    "* 實務研究中，誤差在10%的命中率為50%，而誤差在20%的命中率為80%才符合自動大量估價模型命中率的標準。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定義函式: 計算出預測值落在誤差10%內之命中率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate10(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    res = np.abs(y_true - y_pred)\n",
    "    hit = []\n",
    "    count = 0\n",
    "    for i in res:\n",
    "        if i < 0.1 * y_true[count]:\n",
    "            hit.append(1)\n",
    "        else:\n",
    "            hit.append(0)\n",
    "        count += 1\n",
    "    return sum(hit)/len(y_true)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定義函式: 計算出預測值落在誤差11%內之命中率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate11(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    res = np.abs(y_true - y_pred)\n",
    "    hit = []\n",
    "    count = 0\n",
    "    for i in res:\n",
    "        if i < 0.11 * y_true[count]:\n",
    "            hit.append(1)\n",
    "        else:\n",
    "            hit.append(0)\n",
    "        count += 1\n",
    "    return sum(hit)/len(y_true)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定義函式: 計算出預測值落在誤差20%內之命中率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate20(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    res = np.abs(y_true - y_pred)\n",
    "    hit = []\n",
    "    count = 0\n",
    "    for i in res:\n",
    "        if i < 0.2 * y_true[count]:\n",
    "            hit.append(1)\n",
    "        else:\n",
    "            hit.append(0)\n",
    "        count += 1\n",
    "    return sum(hit)/len(y_true)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 命中率結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "誤差在10%的命中率為: 47.91464597478176 %\n",
      "誤差在11%的命中率為: 51.35790494665373 %\n",
      "誤差在12%的命中率為: 54.31619786614937 %\n",
      "誤差在20%的命中率為: 75.80019398642095 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"誤差在10%的命中率為: {hit_rate10(y_test,result)} %\")\n",
    "print(f\"誤差在11%的命中率為: {hit_rate11(y_test,result)} %\")\n",
    "print(f\"誤差在20%的命中率為: {hit_rate20(y_test,result)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 精度評估\n",
    "* 由AVM模型得知，預測估計值在誤差11%內的命中率達51.35%，雖說已有一定成果，本研究之模型參數可能需再做調整。實務研究中符合自動大量估價模型命中率的標準為:誤差10%內的命中率達50%(本研究模型為47.9%)、誤差20%內的命中率達80%(本研究模型為75.8%)，可見本研究模型仍近乎達到自動大量估價模型命中率之標準。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 未來展望\n",
    "\n",
    "1. 資料樣本的多寡是影響的重要因素之一，由於必須考量地區、時間、離群子與房屋類型，所以我們刪除了大半筆資料，導致我們的訓練資料不足一萬筆，進而導致預測結果可能沒有達到最優解。所以我們以後若需要改良程式，蒐集筆數多且完善的資料是我們需要多下工夫的地方。\n",
    "\n",
    "2. 本次報告透過房屋的特徵與價格來訓練資料，但買賣房屋還是有許多無法量化的因素，例如風水問題、該地區幾年前與幾年後的公設發展，甚至政治因素、物價因素、都市計畫等等，所以如果也能將這類影響資訊取得客觀量化基準，運用深度學習所建構的預測模型會更符合實際住房的買賣成交情形。\n",
    "\n",
    "3. 本次模型未加入poi因子(位置變數)，可能是影響命中率大小的原因之一，未來將試著納入更多潛在影響不動產交易價格之變數，以及考慮時間因素(成交價格隨著市場行情而改變)，試著將訓練資料整理成時間序列型資料，在模型內先加入RNN(LSTM層)再加入全連結神經網路，藉以提高模型之命中率。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
